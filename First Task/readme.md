
# Using Groq AI with LangChain** ğŸš€

## ğŸ“Œ Overview  
This repository demonstrates how to integrate **Groq AI models** with **LangChain** for AI-powered chat applications. The project utilizes **Llama3-8b-8192** via the `langchain_groq` package.

---

## ğŸ¤– What is LLaMA?  
LLaMA (**Large Language Model Meta AI**) is a family of **AI models developed by Meta** (formerly Facebook AI). These models are designed for **text generation, chatbots, and reasoning tasks**.

### ğŸ”¹ **LLaMA Versions**  
- **LLaMA 1** *(2023)* â€“ Small and efficient, with sizes of **7B, 13B, 33B, and 65B parameters**.  
- **LLaMA 2** *(2023)* â€“ Fully **open-source**, improved accuracy, and available in **7B, 13B, and 70B** sizes.  
- **LLaMA 3** *(2024)* â€“ More advanced and efficient, currently available in **8B and 70B versions**.  

### ğŸ”¹ **Why Use LLaMA?**  
âœ… **Open and flexible** â€“ Ideal for research and commercial projects.  
âœ… **Efficient and powerful** â€“ Works well even on smaller hardware.  
âœ… **Easy to fine-tune** â€“ Can be customized for specific tasks.  

---

## ğŸ›  Installation  

To get started, install the required dependencies:  

```sh
pip install langchain_groq
```

---

## ğŸ“œ Code Explanation  

The following script initializes the **Groq AI model** and invokes it with a prompt.

### 1ï¸âƒ£ Import Necessary Libraries  

```python
from langchain_groq import ChatGroq
from langchain.prompts import ChatPromptTemplate
```
- `ChatGroq`: The LangChain interface for interacting with **Groq AI models**.  
- `ChatPromptTemplate`: Allows the creation of **dynamic prompt templates**.  

### 2ï¸âƒ£ Set Up the Model  

```python
import os

groq_api_key = os.getenv("GROQ_API_KEY")  # Load API key from environment variable
llm2 = ChatGroq(groq_api_key=groq_api_key, model_name="Llama3-8b-8192")
```
ğŸ”¹ **Security Note**: Store the API key securely as an **environment variable** instead of hardcoding it.  

### 3ï¸âƒ£ Define a Prompt Template  

```python
prompt = ChatPromptTemplate.from_template(
    """
    What is the best place to visit in Islamabad?
    {response}
    """
)
```
- This creates a **formatted prompt** where `{response}` is a placeholder.  

### 4ï¸âƒ£ Invoke the Model  

```python
response = llm2.invoke(prompt.format(response=""))
print("Response:", response)
```
- The `{response}` placeholder is replaced with an **empty string**.  
- The formatted prompt is sent to the AI model for processing.  
- The response is printed to the console.  

---

## â–¶ Running the Script  

Make sure your **Groq API key** is set in your environment variables:  

```sh
export GROQ_API_KEY="your_api_key_here"
```

Then, run the script:  

```sh
python script.py
```

---

## ğŸ“Œ Expected Output  

The script will return a response from the **AI model**, suggesting the best places to visit in **Islamabad**.

---

## ğŸ“ Notes  

ğŸ”¹ Ensure that your **API key is valid and active**.  
ğŸ”¹ If you encounter issues, check the `response` object structure to debug.  

---

## ğŸ“œ License  

This project is **open-source** and available under the **MIT License**.  

---

ğŸš€ **Happy Coding!** ğŸ’¡